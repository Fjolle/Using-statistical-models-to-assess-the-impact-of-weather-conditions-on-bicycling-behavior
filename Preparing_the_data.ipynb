{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Libraries imported\n",
    "\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import requests\n",
    "from xml.etree import ElementTree as ET\n",
    "import datetime\n",
    "format = \"%d/%m/%Y %H:%M\"\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import json\n",
    "import numpy as np\n",
    "import urllib\n",
    "from darksky import forecast\n",
    "import datetime\n",
    "import forecastio\n",
    "import getpass\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f9797600c863>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mbike_journey_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id_hours\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbike_journey_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id_hours\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pandas Profiling Report'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'style'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'full_width'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mbike_journey_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bike_journey_data_27_mar_2020.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Historical Bike Journey Data\n",
    "\n",
    "## Read list of names of all files from a separate CSV\n",
    "with open('tfl_bike_trips.csv', 'r') as f:\n",
    "    csv_list = f.read().splitlines()\n",
    "\n",
    "## Downloading all of the bike journey CSV files for 2019 and appending to one dataset\n",
    "website = 'http://cycling.data.tfl.gov.uk/usage-stats/'\n",
    "\n",
    "url_list = [website + urllib.parse.quote(x) for x in csv_list]\n",
    "dfs = (pd.read_csv(url) for url in url_list)\n",
    "bike_journey_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "bike_journey_data['Start Date']= bike_journey_data['Start Date']\n",
    "bike_journey_data['End Date']=bike_journey_data['End Date']\n",
    "bike_journey_data['Start Date Converted']= pd.to_datetime(bike_journey_data['Start Date'], format=format).dt.date\n",
    "bike_journey_data['End Date Converted']= pd.to_datetime(bike_journey_data['End Date'], format=format).dt.date\n",
    "bike_journey_data['Hours']= pd.to_datetime(bike_journey_data['Start Date'], format=format).dt.hour\n",
    "bike_journey_data['Week Day']= pd.to_datetime(bike_journey_data['Start Date'], format=format).dt.weekday\n",
    "bike_journey_data['Day']= pd.to_datetime(bike_journey_data['Start Date'], format=format).dt.day\n",
    "bike_journey_data['Month']= pd.to_datetime(bike_journey_data['Start Date'], format=format).dt.month\n",
    "bike_journey_data['Year']= pd.to_datetime(bike_journey_data['Start Date'], format=format).dt.year\n",
    "bike_journey_data['Duration in minutes']=bike_journey_data['Duration']/60\n",
    "bike_journey_data['id'] = bike_journey_data['Year'].map(str) + '-' + bike_journey_data['Month'].map(str) + '-' + bike_journey_data['Day'].map(str)\n",
    "bike_journey_data[\"id\"] = bike_journey_data[\"id\"].astype(str)\n",
    "bike_journey_data['id_hours'] = bike_journey_data['Start Date Converted'].map(str)+ '-' + bike_journey_data['Hours'].map(str)\n",
    "bike_journey_data[\"id_hours\"] = bike_journey_data[\"id_hours\"].astype(str)\n",
    "\n",
    "bike_journey_data.to_csv('bike_journey_data_27_mar_2020.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real time Bike location data\n",
    "\n",
    "locu_api='0562cc774cc1e0842794be372d6fd545'\n",
    "\n",
    "url='https://api.tfl.gov.uk/BikePoint?app_id=bd90e5e6&app_key=0562cc774cc1e0842794be372d6fd545'\n",
    "json_obj=urllib.request.urlopen(url)\n",
    "\n",
    "data=json.load(json_obj)\n",
    "\n",
    "value1 =[]\n",
    "for item1 in range(len(data)):\n",
    "    for item2 in range(len(data[item1]['additionalProperties'])):\n",
    "        if (data[item1]['additionalProperties'][item2]['key'])==\"NbDocks\":\n",
    "            value1.append(data[item1]['additionalProperties'][item2]['value'])\n",
    "\n",
    "value2 =[]\n",
    "for item1 in range(len(data)):\n",
    "    for item2 in range(len(data[item1]['additionalProperties'])):\n",
    "        if (data[item1]['additionalProperties'][item2]['key'])==\"NbEmptyDocks\":\n",
    "            value2.append(data[item1]['additionalProperties'][item2]['value'])\n",
    "            \n",
    "value3 =[]\n",
    "for item1 in range(len(data)):\n",
    "     value3.append(data[item1]['commonName'])\n",
    "        \n",
    "value4 =[]\n",
    "for item1 in range(len(data)):\n",
    "     value4.append(data[item1]['lat'])\n",
    "        \n",
    "value5 =[]\n",
    "for item1 in range(len(data)):\n",
    "     value5.append(data[item1]['lon'])\n",
    "        \n",
    "\n",
    "value6 =[]\n",
    "for item1 in range(len(data)):\n",
    "    for item2 in range(len(data[item1]['additionalProperties'])):\n",
    "        if (data[item1]['additionalProperties'][item2]['key'])==\"NbBikes\":\n",
    "            value6.append(data[item1]['additionalProperties'][item2]['value']) \n",
    "            \n",
    "value7 =[]\n",
    "for item1 in range(len(data)):\n",
    "     value7.append(data[item1]['id'])\n",
    "\n",
    "ID=[]\n",
    "for value in value7:\n",
    "    ID.append(value[11:])\n",
    "    \n",
    "         \n",
    "#d = {'Bike point': value3, 'No of avail Bikes': value4, 'No empty docks' : value2, 'Total docks': value1}\n",
    "\n",
    "bike_location_data= pd.DataFrame(list(zip(value1, value2, value3, \n",
    "                                value4, value5, value6, ID)), \n",
    "                columns = [\"Capacity\",\"Empty docks\",\"Bike station\",\"Lat\", \"Lon\", \"Avail bikes\", \"id\"])\n",
    "\n",
    "bike_location_data[\"id\"] = bike_location_data[\"id\"].astype(int)\n",
    "\n",
    "bike_location_data.to_csv('bike_location_data_27_March_2020.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Weather Data from DarkSky\n",
    "\n",
    "api_key = ('4bd2f4701fdba6c093dc1857f669bd23')\n",
    "lat = 51.51\n",
    "lng = -0.13\n",
    "date = datetime.datetime(2019,1,1)\n",
    "forecast = forecastio.load_forecast(api_key, lat, lng, time=date)\n",
    "attributes = [\"temperature\", \"precipIntensity\", \"humidity\", \"windSpeed\", \"visibility\"]\n",
    "\n",
    "times = []\n",
    "data = {}\n",
    "for attr in attributes:\n",
    "    data[attr] = []\n",
    "\n",
    "start = datetime.datetime(2019, 1, 1)\n",
    "for offset in range(1, 365):\n",
    "    forecast = forecastio.load_forecast('4bd2f4701fdba6c093dc1857f669bd23', '51.51', '-0.13', time=start+datetime.timedelta(offset), units=\"uk\")\n",
    "    h = forecast.hourly()\n",
    "    d = h.data\n",
    "    for p in d:\n",
    "        times.append(p.time)\n",
    "        try:\n",
    "            for i in attributes:\n",
    "                data[i].append(p.d[i])\n",
    "        except:\n",
    "            print(KeyError)\n",
    "\n",
    "weather_data = pd.DataFrame(data, index=times)\n",
    "\n",
    "weather_data.index.names = ['Date']\n",
    "\n",
    "weather_data['Date']=weather_data.index\n",
    "weather_data['Date Converted']= pd.to_datetime(weather_data['Date'], format=format).dt.date\n",
    "weather_data['Hours']= pd.to_datetime(weather_data['Date'], format=format).dt.hour\n",
    "weather_data[\"Hours\"].replace(0, 24)\n",
    "weather_data['Day']= pd.to_datetime(weather_data['Date'], format=format).dt.day\n",
    "weather_data['Month']= pd.to_datetime(weather_data['Date'], format=format).dt.month\n",
    "weather_data['Year']= pd.to_datetime(weather_data['Date'], format=format).dt.year\n",
    "weather_data['id'] = weather_data['Year'].map(str) + '-' + weather_data['Month'].map(str) + '-' + weather_data['Day'].map(str).map(str)\n",
    "weather_data[\"id\"] = weather_data[\"id\"].astype(str)\n",
    "weather_data[\"Hours\"] = weather_data[\"Hours\"].astype(str)\n",
    "weather_data=weather_data.drop(columns=['Day', 'Year', 'Month', 'Date'])\n",
    "weather_data['id_Hours'] = weather_data['Date Converted'].map(str) + '-' + weather_data['Hours'].map(str)\n",
    "weather_data[\"id_Hours\"] = weather_data[\"id_Hours\"].astype(str)\n",
    "\n",
    "#%matplotlib inline\n",
    "#plt.style.use('ggplot')\n",
    "#weather_data.plot(subplots=True);\n",
    "\n",
    "weather_data.to_csv('weather_data_27_mar_2020.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Combine journey data with location data\n",
    "    \n",
    "'''bike_data= bike_journey_data.merge(right =bike_location_data,\n",
    "                             how = 'inner',\n",
    "                             left_on = 'StartStation Id',\n",
    "                             right_on = 'id')\n",
    "\n",
    "pd.set_option('display.max_columns', 999)\n",
    "bike_data=bike_data.drop(columns=['id_y','Year'])\n",
    "bike_data.sort_values(by=['id_x'])'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
